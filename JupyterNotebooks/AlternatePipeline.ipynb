{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RGfbpvGyrpsx"
      },
      "outputs": [],
      "source": [
        "# rest of imports\n",
        "import numpy as np\n",
        "from numpy import load, savez_compressed\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from os import listdir\n",
        "import re\n",
        "from cuml.decomposition import IncrementalPCA as IncrementalPCA_CUML\n",
        "import cupy as cp\n",
        "import cupyx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mxTnsUEGruE7"
      },
      "outputs": [],
      "source": [
        "# LFW_IPCA Class Definition\n",
        "class LFW_IncrementalPCA(IncrementalPCA):\n",
        "    def __init__(self, dataset_paths: list[str], n_components: int, batch_size: int = 16):\n",
        "        super(LFW_IncrementalPCA, self).__init__(\n",
        "            n_components=n_components,\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "        self.dataset_paths = dataset_paths\n",
        "        self.n_components_ = n_components\n",
        "\n",
        "    def start_fit(self, display_progress: bool=False):\n",
        "        r\"\"\" Begins an incremental fit on the given dataset paths\n",
        "            Args:\n",
        "                display_progress (bool): Whether to display incremental progress of the fit\n",
        "\n",
        "            Returns:\n",
        "                None\n",
        "        \"\"\"\n",
        "\n",
        "        for i, file in enumerate(self.dataset_paths):\n",
        "            data = load(file)\n",
        "            X_train = data['arr_0']\n",
        "            X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "            if (display_progress):\n",
        "                print(f\"i = {i} | Partial fit on X_train of sizes {X_train.shape}\")\n",
        "            self.partial_fit(X_train)\n",
        "\n",
        "    def get_embeddings(self, display_progress: bool=False):\n",
        "        r\"\"\" Transforms the given datasets into embeddings and returns them\n",
        "            Args:\n",
        "                display_progress (bool): Whether to display final progress of embeddings\n",
        "\n",
        "            Returns:\n",
        "                X_train_pca (np.array): X_train pca embeddings\n",
        "                Y_train_pca (np.array): Y_train labels\n",
        "                X_test_pca (np.array): X_test pca embeddings\n",
        "                Y_test_pca (np.array): Y_test labels\n",
        "        \"\"\"\n",
        "\n",
        "        X_train_pca = X_test_pca = np.zeros((0, self.n_components_))\n",
        "        Y_train_pca = Y_test_pca = np.zeros((0, 1))\n",
        "\n",
        "        for i, file in enumerate(self.dataset_paths):\n",
        "            data = load(file)\n",
        "            X_train, Y_train, X_test, Y_test = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "            X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "            X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "            Y_train = Y_train.reshape(-1,1)\n",
        "            Y_test = Y_test.reshape(-1,1)\n",
        "\n",
        "            X_train_pca = np.vstack((X_train_pca, self.transform(X_train)))\n",
        "            X_test_pca = np.vstack((X_test_pca, self.transform(X_test)))\n",
        "\n",
        "            Y_train_pca = np.vstack((Y_train_pca, Y_train))\n",
        "            Y_test_pca = np.vstack((Y_test_pca, Y_test))\n",
        "\n",
        "        if display_progress:\n",
        "            print(f\"X_train_pca shape {X_train_pca.shape} | X_test_pca {X_test_pca.shape} | Y_train_pca shape {Y_train_pca.shape} | Y_test_pca {Y_test_pca.shape}\")\n",
        "        return X_train_pca, Y_train_pca, X_test_pca, Y_test_pca\n",
        "\n",
        "    def save_embeddings(self, save_path: str, display_progress: bool=False):\n",
        "        r\"\"\" Transforms the given datasets into embeddings and returns them\n",
        "            Args:\n",
        "            save_path (str): npz file path to save the embeddings to\n",
        "                display_progress (bool): Whether to display final progress of embeddings\n",
        "\n",
        "            Returns:\n",
        "                None\n",
        "        \"\"\"\n",
        "\n",
        "        X_train_pca = X_test_pca = np.zeros((0, self.n_components_))\n",
        "        Y_train_pca = Y_test_pca = np.zeros((0, 1))\n",
        "\n",
        "        for i, file in enumerate(self.dataset_paths):\n",
        "            data = load(file)\n",
        "            X_train, Y_train, X_test, Y_test = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "            X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "            X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "            Y_train = Y_train.reshape(-1,1)\n",
        "            Y_test = Y_test.reshape(-1,1)\n",
        "\n",
        "            X_train_pca = np.vstack((X_train_pca, self.transform(X_train)))\n",
        "            X_test_pca = np.vstack((X_test_pca, self.transform(X_test)))\n",
        "\n",
        "            Y_train_pca = np.vstack((Y_train_pca, Y_train))\n",
        "            Y_test_pca = np.vstack((Y_test_pca, Y_test))\n",
        "\n",
        "        if display_progress:\n",
        "            print(f\"X_train_pca shape {X_train_pca.shape} | X_test_pca {X_test_pca.shape} | Y_train_pca shape {Y_train_pca.shape} | Y_test_pca {Y_test_pca.shape}\")\n",
        "\n",
        "        savez_compressed(save_path, X_train_pca, Y_train_pca, X_test_pca, Y_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6ojhOKePtII8"
      },
      "outputs": [],
      "source": [
        "# LFW_IPCA Class Definition\n",
        "class LFW_IncrementalPCA_CUML(IncrementalPCA_CUML):\n",
        "    def __init__(self, *args, dataset_paths: list[str] = [], n_components: int, batch_size: int = 16):\n",
        "        super(LFW_IncrementalPCA_CUML, self).__init__(\n",
        "            args,\n",
        "            n_components=n_components,\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "        self.dataset_paths = dataset_paths\n",
        "        self.n_components_ = n_components\n",
        "\n",
        "    def start_fit(self, display_progress: bool=False):\n",
        "        r\"\"\" Begins an incremental fit on the given dataset paths\n",
        "            Args:\n",
        "                display_progress (bool): Whether to display incremental progress of the fit\n",
        "\n",
        "            Returns:\n",
        "                None\n",
        "        \"\"\"\n",
        "\n",
        "        for i, file in enumerate(self.dataset_paths):\n",
        "            data = load(file)\n",
        "            X_train = data['arr_0']\n",
        "            X_train = X_train.reshape(X_train.shape[0], -1).astype('float32')\n",
        "\n",
        "            X_train_gpu = cp.asarray(X_train)\n",
        "            if (display_progress):\n",
        "                print(f\"i = {i} | Partial fit on X_train of sizes {X_train.shape}\")\n",
        "            self.partial_fit(X_train_gpu)\n",
        "            # del X_train_gpu\n",
        "            # cp._default_memory_pool.free_all_blocks()\n",
        "\n",
        "    def get_embeddings(self, display_progress: bool=False):\n",
        "        r\"\"\" Transforms the given datasets into embeddings and returns them\n",
        "            Args:\n",
        "                display_progress (bool): Whether to display final progress of embeddings\n",
        "\n",
        "            Returns:\n",
        "                X_train_pca (np.array): X_train pca embeddings\n",
        "                Y_train_pca (np.array): Y_train labels\n",
        "                X_test_pca (np.array): X_test pca embeddings\n",
        "                Y_test_pca (np.array): Y_test labels\n",
        "        \"\"\"\n",
        "\n",
        "        X_train_pca = X_test_pca = np.zeros((0, self.n_components_))\n",
        "        Y_train_pca = Y_test_pca = np.zeros((0, 1))\n",
        "\n",
        "        for i, file in enumerate(self.dataset_paths):\n",
        "            data = load(file)\n",
        "            X_train, Y_train, X_test, Y_test = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "            X_train = X_train.reshape(X_train.shape[0], -1).astype('float32')\n",
        "            X_test = X_test.reshape(X_test.shape[0], -1).astype('float32')\n",
        "            Y_train = Y_train.reshape(-1,1)\n",
        "            Y_test = Y_test.reshape(-1,1)\n",
        "\n",
        "            X_train_pca = np.vstack((X_train_pca, self.transform(X_train)))\n",
        "            X_test_pca = np.vstack((X_test_pca, self.transform(X_test)))\n",
        "\n",
        "            Y_train_pca = np.vstack((Y_train_pca, Y_train))\n",
        "            Y_test_pca = np.vstack((Y_test_pca, Y_test))\n",
        "\n",
        "        if display_progress:\n",
        "            print(f\"X_train_pca shape {X_train_pca.shape} | X_test_pca {X_test_pca.shape} | Y_train_pca shape {Y_train_pca.shape} | Y_test_pca {Y_test_pca.shape}\")\n",
        "        return X_train_pca, Y_train_pca, X_test_pca, Y_test_pca\n",
        "\n",
        "    def save_embeddings(self, save_path: str, display_progress: bool=False):\n",
        "        r\"\"\" Transforms the given datasets into embeddings and returns them\n",
        "            Args:\n",
        "            save_path (str): npz file path to save the embeddings to\n",
        "                display_progress (bool): Whether to display final progress of embeddings\n",
        "\n",
        "            Returns:\n",
        "                None\n",
        "        \"\"\"\n",
        "\n",
        "        X_train_pca = X_test_pca = np.zeros((0, self.n_components_))\n",
        "        Y_train_pca = Y_test_pca = np.zeros((0, 1))\n",
        "\n",
        "        for i, file in enumerate(self.dataset_paths):\n",
        "            data = load(file)\n",
        "            X_train, Y_train, X_test, Y_test = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "            X_train = X_train.reshape(X_train.shape[0], -1).astype('float32')\n",
        "            X_test = X_test.reshape(X_test.shape[0], -1).astype('float32')\n",
        "            Y_train = Y_train.reshape(-1,1)\n",
        "            Y_test = Y_test.reshape(-1,1)\n",
        "\n",
        "            X_train_pca = np.vstack((X_train_pca, cp.asnumpy(self.transform(cp.asarray(X_train)))))\n",
        "            X_test_pca = np.vstack((X_test_pca, cp.asnumpy(self.transform(cp.asarray(X_test)))))\n",
        "\n",
        "            Y_train_pca = np.vstack((Y_train_pca, Y_train))\n",
        "            Y_test_pca = np.vstack((Y_test_pca, Y_test))\n",
        "\n",
        "        if display_progress:\n",
        "            print(f\"X_train_pca shape {X_train_pca.shape} | X_test_pca {X_test_pca.shape} | Y_train_pca shape {Y_train_pca.shape} | Y_test_pca {Y_test_pca.shape}\")\n",
        "\n",
        "        savez_compressed(save_path, X_train_pca, Y_train_pca, X_test_pca, Y_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KuDNlZzvXgG",
        "outputId": "6a56cbaa-60c2-4378-e668-5d378bb0e400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_pca shape (0, 150) | X_test_pca (0, 150) | Y_train_pca shape (0, 1) | Y_test_pca (0, 1)\n",
            "Time for cuml method to complete 0.0011479854583740234\n",
            "X_train_pca shape (0, 150) | X_test_pca (0, 150) | Y_train_pca shape (0, 1) | Y_test_pca (0, 1)\n",
            "Time for default method to complete 0.0005319118499755859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_17054/3847819363.py:4: FutureWarning: Pass handle=() as keyword args. From version 21.06, passing these as positional arguments will result in an error\n",
            "  super(LFW_IncrementalPCA_CUML, self).__init__(\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from time import time\n",
        "cp._default_memory_pool.free_all_blocks()\n",
        "n_components = 150\n",
        "dataset_npz_filenames = []\n",
        "reg_expr = '^lfw-deepfunneled-dataset-cuml_[0-9]{4}.npz'\n",
        "for file in listdir('./'):\n",
        "    if re.search(reg_expr, file):\n",
        "        dataset_npz_filenames.append(file)\n",
        "\n",
        "start = time()\n",
        "# create an lfw_ipca instance and give the label of datasets and desired n_componentes\n",
        "lfw_ipca = LFW_IncrementalPCA_CUML(dataset_paths=dataset_npz_filenames, n_components=n_components)\n",
        "\n",
        "# start the fit on the entire datasets given\n",
        "lfw_ipca.start_fit(display_progress=True)\n",
        "\n",
        "# save the embeddings as a compressed .npz file\n",
        "lfw_ipca.save_embeddings(\"lfw-deepfunneled-pca-embeddings-50-cuml.npz\", display_progress=True)\n",
        "end = time()\n",
        "print(f\"Time for cuml method to complete {end - start}\")\n",
        "\n",
        "start = time()\n",
        "# create an lfw_ipca instance and give the label of datasets and desired n_componentes\n",
        "lfw_ipca = LFW_IncrementalPCA(dataset_npz_filenames, n_components=n_components)\n",
        "\n",
        "# start the fit on the entire datasets given\n",
        "lfw_ipca.start_fit(display_progress=True)\n",
        "\n",
        "# save the embeddings as a compressed .npz file\n",
        "lfw_ipca.save_embeddings(\"lfw-deepfunneled-pca-embeddings-150-default.npz\", display_progress=True)\n",
        "end = time()\n",
        "print(f\"Time for default method to complete {end - start}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
